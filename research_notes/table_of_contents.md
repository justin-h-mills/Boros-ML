# Table of Contents

***

## Activation Functions

***

### Rectifier Activation Functions

1. [Rectified Linear Unit (ReLU)](/research_notes/activation_functions/rectifier_activation_functions/relu.md)
2. [Leaky Rectified Linear Unit (Leaky ReLU)](/research_notes/activation_functions/rectifier_activation_functions/leaky_relu.md)
3. [Parametric ReLU (PReLU)](/research_notes/activation_functions/rectifier_activation_functions/prelu.md)

### Smooth Activation Functions

1. [Exponential Linear Unit (ELU)](/research_notes/activation_functions/smooth_activation_functions/elu.md)
2. [Gaussian Error Linear Unit (GELU)](/research_notes/activation_functions/smooth_activation_functions/gelu.md)
3. [Sigmoid-Weighted Linear Unit (SiLU)](/research_notes/activation_functions/smooth_activation_functions/silu.md)

### Sigmoid Activation Functions

1. [Sigmoid](/research_notes/activation_functions/sigmoid_activation_functions/sigmoid.md)
2. [Hyperbolic Tangent (Tanh)](/research_notes/activation_functions/sigmoid_activation_functions/tanh.md)

### Other Activation Functions

1. [Gated Linear Unit (GLU)](/research_notes/activation_functions/other_activation_functions/glu.md)
2. [Softmax](/research_notes/activation_functions/other_activation_functions/softmax.md)